{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX A: Data Cleaning, Data scraping, and Network creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import re\n",
    "import json, urllib\n",
    "import sys\n",
    "import io\n",
    "import pickle\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Wikipedia pages function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(df,nodetype):\n",
    "    \"\"\" This functions Downloads the Wikipages \n",
    "    from Wikilinks column in the dataframe\n",
    "    \n",
    "    Input: dataframe and nodetype\n",
    "    -------------------------------\n",
    "    Output: \n",
    "    \"\"\"\n",
    "    for i in range(df.shape[0]):                                             # Run through all wikilinks in dataframe \n",
    "        baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "        action = \"action=query\"\n",
    "        title = \"titles=\" + df[\"WikiLink\"].iloc[i]\n",
    "        content = \"prop=revisions&rvprop=content\"\n",
    "        dataformat =\"format=json\"\n",
    "        query = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat).encode('ascii', 'ignore').decode('ascii')\n",
    "        \n",
    "        wikiresponse = urllib.request.urlopen(query)                         \n",
    "        wikidata = wikiresponse.read()                                       \n",
    "        wikitext = wikidata.decode('utf-8')\n",
    "        wikijson = json.loads(wikitext)['query']['pages']\n",
    "        key = list(wikijson.keys())[0]\n",
    "\n",
    "        if key != '-1':                                                      # If Key = '-1',the wikilink does not exist \n",
    "            wiki_Print = wikijson[key]['revisions'][0]['*']\n",
    "            sys.stdout = open(nodetype + \"_\" + df[\"WikiLink\"].iloc[i] + \".txt\", \"w\",encoding=\"utf-8\")\n",
    "            print(wiki_Print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Events dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events_file(events):\n",
    "    \"\"\" This functions takes the .csv file --> \n",
    "    Convert it into a panda dataframe -->\n",
    "    Do some datacleaning --> \n",
    "    add the WikiLink column\n",
    "    \n",
    "    Input: 1.csv files\n",
    "    -------------------------------\n",
    "    Output: 1 dataframes\n",
    "    \"\"\"    \n",
    "    df_events = pd.read_csv(events, sep = ';', encoding = 'latin-1', dtype = object)         # Convert events.csv to panda dataframe\n",
    "    df_events['WikiLink'] = df_events['sport']+\"_at_the_2016_Summer_Olympics\"                # Add a column for WikiLinks\n",
    "    df_events['WikiLink'] = df_events['WikiLink'].str.replace('canoe', 'canoeing')           # Replace canou (for Matching Wikilink)\n",
    "    df_events['WikiLink'] = df_events['WikiLink'].str.replace('hockey', 'field hockey')      # Replace hockey (for Matching Wikilink)\n",
    "    df_events['WikiLink'] = df_events['WikiLink'].str.replace('synchronised','synchronized') # Replace synchronised (for Matching Wikilink)\n",
    "    df_events['WikiLink'] = df_events['WikiLink'].str.replace('\\s', '_')                     # Replase space with _\n",
    "    df_events = df_events.drop_duplicates(subset = [\"WikiLink\"])                             # drop duplicates\n",
    "    df_events = df_events.dropna()                                                           # Remove NanN\n",
    "    \n",
    "    return df_events\n",
    "\n",
    "df_e = read_events_file('events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download events Wikipedia pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(df_e,'events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Country dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Country_file(countries):\n",
    "    \"\"\" This functions takes the country.csv \n",
    "    Convert it into a panda dataframe -->\n",
    "    Do some datacleaning --> \n",
    "    add the WikiLink column\n",
    "    \n",
    "    Input: .csv files\n",
    "    -------------------------------\n",
    "    Output: dataframes\n",
    "    \"\"\"\n",
    "    df_countries = pd.read_csv(countries, sep = ';',   encoding = 'latin-1', dtype = object) # Convert countries.csv into panda dataframe\n",
    "    df_countries['WikiLink'] = df_countries['country']+\"_at_the_2016_Summer_Olympics\"        # Add a column for WikiLinks\n",
    "    df_countries['country2'] = df_countries['country']                                       # Add a column country2 (Will be used for finding athletes WikiLink)\n",
    "    df_countries['country2'] = df_countries['country2'].str.replace('\\s', '_')               # Replase space with _\n",
    "    df_countries['WikiLink'] = df_countries['WikiLink'].str.replace('\\s', '_')               # Replase space with _\n",
    "    df_countries['WikiLink'] = df_countries['WikiLink'].str.replace(\"*\", \"\")                 # Remove *\n",
    "    df_countries = df_countries.dropna()                                                     # Remove NanN\n",
    "    \n",
    "    return df_countries\n",
    "\n",
    "df_c = read_Country_file('countries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Countries wikipedia pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(df_c,'countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Athletes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_athletes_file(athletes):\n",
    "    \"\"\" This functions takes the .csv file --> \n",
    "    Convert it into a panda dataframe -->\n",
    "    Do some datacleaning \n",
    "    \n",
    "    Input: 1 .csv files\n",
    "    -------------------------------\n",
    "    Output: 1 dataframes\n",
    "    \"\"\"\n",
    "  \n",
    "    df_athletes = pd.read_csv(athletes, sep = ',',   encoding = 'utf-8', dtype = object)     # Convert athletes.csv to panda dataframe\n",
    "    df_athletes['name2'] = df_athletes['name']                                               # Add a column name2 (Will be used for finding athletes WikiLink)\n",
    "    df_athletes['name2'] = df_athletes['name2'].str.replace('\\s', '_')                       # Replase space with _\n",
    "    df_athletes = df_athletes.dropna()                                                       # Remove NanN\n",
    "                                                                                \n",
    "    \n",
    "    return df_athletes\n",
    "\n",
    "df_a = read_athletes_file('athletes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the athlete dataframe with wikilink found in the already downloaded country Wikipedia pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Athlet_WikiLink(df1, df2):\n",
    "    \"\"\" This functions finds the athletes wikilinks by \n",
    "    find all wikilinks from the coutries wikipages. \n",
    "    If the wikilinks matches a name from the athletes dataframe\n",
    "    save the wikilink in a list.\n",
    "    \n",
    "    Input: athletes dataframe, countries dataframe\n",
    "    -------------------------------\n",
    "    Output: list with athletes Wikilinks\n",
    "    \"\"\"\n",
    "    A_WikiLink = []                                                                          # Create an empty list\n",
    "    for i in df2['country2']:                                                                # Run through all countries\n",
    "        f = io.open('countries_'+ i + '_at_the_2016_Summer_Olympics.txt','r',encoding = 'utf-8').read() # Open the file\n",
    "        links = re.findall(\"\\[\\[(.*?)\\]\\]\", f)                                               # Find all links\n",
    "        links = [x.replace(' ','_') for x in links]                                          # Replase space with _\n",
    "        links = [s.split('|') for s in links]                                                # Split the links by the '|'\n",
    "\n",
    "        for j in range(len(links)):                                                          # Run through all links\n",
    "                if len(links[j]) == 1:                                                       # If the name and the links are the same\n",
    "                    if len(df1.loc[df1['name2'] == links[j][0]]) >= 1:                       # If the link excist in the athletes dataframe\n",
    "                        A_WikiLink.append([df1.at[df1.loc[df1['name2'] == links[j][0]].index[0],'id'],links[j][0]]) # append the wikilink and the 'id' number to the list\n",
    "                elif len(links[j]) == 2:                                                     # If the name and the links are not the same\n",
    "                    if len(df1.loc[df1['name2'] == links[j][1]]) >= 1:                       # If the link excist in the athletes dataframe\n",
    "                        A_WikiLink.append([df1.at[df1.loc[df1['name2'] == links[j][1]].index[0],'id'],links[j][0]]) # append the wikilink and the 'id' number to the list\n",
    "    return A_WikiLink\n",
    "\n",
    "A_WikiLink = Athlet_WikiLink(df_a,df_c)                           # Run Function\n",
    "\n",
    "df_if = pd.DataFrame(A_WikiLink, columns = ['id', 'WikiLink'])    # Convert wikilink list into panda dataframe\n",
    "df_a = df_a.merge(df_if)                                          # Merge wikilink dataframe and athletes dataframe\n",
    "df_a = df_a.drop_duplicates()                                     # Drop duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the atheletes wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(df_a,'athletes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the wikilinks if athletes wikilink includes  #REDIRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Athlet_REDIRECT_WikiLink(df1):\n",
    "    \"\"\" This functions finds all athelets wikipedia pages\n",
    "    that contain '#REDIRECT' and add the correct wikilink to a list.\n",
    "    \n",
    "    Input: athletes dataframe\n",
    "    -------------------------------\n",
    "    Output: list with correct athletes Wikilinks\n",
    "    \"\"\"\n",
    "    RE_WikiLink = []                                                                          # Create an empty list\n",
    "    for i in df1['WikiLink']:                                                                 # Run through all atheletes\n",
    "        f = io.open('athletes_'+ i + '.txt','r',encoding = 'utf-8').read()                    # Open the file\n",
    "        if len(re.findall(\"#REDIRECT\", f)) > 0:                                               # If #REDIRECT\n",
    "            links = re.findall(\"\\[\\[(.*?)\\]\\]\", f)                                            # Find the new links\n",
    "            links = [x.replace(' ','_') for x in links]                                       # Replase space with _\n",
    "            \n",
    "            for j in range(len(links)):                                                       # Run through all links                                                     # If the name and the links are the same\n",
    "                if len(df1.loc[df1['WikiLink'] == i]) >= 1:                                   # If the link excist in the athletes dataframe\n",
    "                        RE_WikiLink.append([df1.at[df1.loc[df1['WikiLink'] == i].index[0],'id'], links[j]]) # append the wikilink and the 'id' number to the list\n",
    "               \n",
    "    return RE_WikiLink\n",
    "\n",
    "RE_WikiLink = Athlet_REDIRECT_WikiLink(df_a)                         # Run Function\n",
    "df_if = pd.DataFrame(RE_WikiLink, columns = ['id', 'RE_WikiLink'])   # Convert wikilink list into panda dataframe\n",
    "df_a_RE = df_a.merge(df_if)                                          # Merge wikilink dataframe and athletes dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all atheletes that have af REDIRECT wikilink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>nationality</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>sport</th>\n",
       "      <th>gold</th>\n",
       "      <th>silver</th>\n",
       "      <th>bronze</th>\n",
       "      <th>name2</th>\n",
       "      <th>WikiLink</th>\n",
       "      <th>RE_WikiLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5763609</td>\n",
       "      <td>Abdullah Abkar Mohammed</td>\n",
       "      <td>KSA</td>\n",
       "      <td>male</td>\n",
       "      <td>1/1/97</td>\n",
       "      <td>1.72</td>\n",
       "      <td>73</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abdullah_Abkar_Mohammed</td>\n",
       "      <td>Abdullah_Abkar_Mohammed</td>\n",
       "      <td>Abdullah_Abkar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750356217</td>\n",
       "      <td>Aida Shanaeva</td>\n",
       "      <td>RUS</td>\n",
       "      <td>female</td>\n",
       "      <td>4/23/86</td>\n",
       "      <td>1.73</td>\n",
       "      <td>63</td>\n",
       "      <td>fencing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aida_Shanaeva</td>\n",
       "      <td>Aida_Shanaeva</td>\n",
       "      <td>Aida_Shanayeva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>823094336</td>\n",
       "      <td>Aikaterini-Maria Kontochristopoulou</td>\n",
       "      <td>GRE</td>\n",
       "      <td>female</td>\n",
       "      <td>6/10/97</td>\n",
       "      <td>1.68</td>\n",
       "      <td>58</td>\n",
       "      <td>fencing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aikaterini-Maria_Kontochristopoulou</td>\n",
       "      <td>Aikaterini-Maria_Kontochristopoulou</td>\n",
       "      <td>Aikaterini_Kontochristopoulou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704825548</td>\n",
       "      <td>Aisha Praught</td>\n",
       "      <td>JAM</td>\n",
       "      <td>female</td>\n",
       "      <td>12/14/89</td>\n",
       "      <td>1.62</td>\n",
       "      <td>50</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aisha_Praught</td>\n",
       "      <td>Aisha_Praught</td>\n",
       "      <td>Aisha_Praught-Leer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374861025</td>\n",
       "      <td>Ajla del Ponte</td>\n",
       "      <td>SUI</td>\n",
       "      <td>female</td>\n",
       "      <td>7/15/96</td>\n",
       "      <td>1.68</td>\n",
       "      <td>56</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ajla_del_Ponte</td>\n",
       "      <td>Ajla_del_Ponte</td>\n",
       "      <td>Ajla_Del_Ponte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>953630497</td>\n",
       "      <td>Yekaterina Smirnova</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>female</td>\n",
       "      <td>5/21/88</td>\n",
       "      <td>1.65</td>\n",
       "      <td>63</td>\n",
       "      <td>canoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yekaterina_Smirnova</td>\n",
       "      <td>Yekaterina_Smirnova(canoeist)</td>\n",
       "      <td>Yekaterina_Smirnova_(canoeist)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>805715080</td>\n",
       "      <td>Yelena Ryabova</td>\n",
       "      <td>TKM</td>\n",
       "      <td>female</td>\n",
       "      <td>11/3/90</td>\n",
       "      <td>1.7</td>\n",
       "      <td>56</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yelena_Ryabova</td>\n",
       "      <td>Yelena_Ryabova</td>\n",
       "      <td>Ýelena_Rýabowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>108168547</td>\n",
       "      <td>Yuki Uchiyama</td>\n",
       "      <td>JPN</td>\n",
       "      <td>female</td>\n",
       "      <td>1/13/98</td>\n",
       "      <td>1.59</td>\n",
       "      <td>49</td>\n",
       "      <td>gymnastics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yuki_Uchiyama</td>\n",
       "      <td>Yuki_Uchiyama_(artistic_gymnast)</td>\n",
       "      <td>Yuki_Uchiyama_(gymnast)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>830255142</td>\n",
       "      <td>Zalina Marghieva</td>\n",
       "      <td>MDA</td>\n",
       "      <td>female</td>\n",
       "      <td>2/5/88</td>\n",
       "      <td>1.7</td>\n",
       "      <td>80</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Zalina_Marghieva</td>\n",
       "      <td>Zalina_Marghieva</td>\n",
       "      <td>Zalina_Petrivskaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>600541319</td>\n",
       "      <td>Zurabi Datunashvili</td>\n",
       "      <td>GEO</td>\n",
       "      <td>male</td>\n",
       "      <td>6/18/91</td>\n",
       "      <td>1.83</td>\n",
       "      <td>75</td>\n",
       "      <td>wrestling</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Zurabi_Datunashvili</td>\n",
       "      <td>Zurabi_Datunashvili</td>\n",
       "      <td>Zurab_Datunashvili</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                 name nationality     sex  \\\n",
       "0      5763609              Abdullah Abkar Mohammed         KSA    male   \n",
       "1    750356217                        Aida Shanaeva         RUS  female   \n",
       "2    823094336  Aikaterini-Maria Kontochristopoulou         GRE  female   \n",
       "3    704825548                        Aisha Praught         JAM  female   \n",
       "4    374861025                       Ajla del Ponte         SUI  female   \n",
       "..         ...                                  ...         ...     ...   \n",
       "236  953630497                  Yekaterina Smirnova         KAZ  female   \n",
       "237  805715080                       Yelena Ryabova         TKM  female   \n",
       "238  108168547                        Yuki Uchiyama         JPN  female   \n",
       "239  830255142                     Zalina Marghieva         MDA  female   \n",
       "240  600541319                  Zurabi Datunashvili         GEO    male   \n",
       "\n",
       "          dob height weight       sport gold silver bronze  \\\n",
       "0      1/1/97   1.72     73   athletics    0      0      0   \n",
       "1     4/23/86   1.73     63     fencing    0      0      0   \n",
       "2     6/10/97   1.68     58     fencing    0      0      0   \n",
       "3    12/14/89   1.62     50   athletics    0      0      0   \n",
       "4     7/15/96   1.68     56   athletics    0      0      0   \n",
       "..        ...    ...    ...         ...  ...    ...    ...   \n",
       "236   5/21/88   1.65     63       canoe    0      0      0   \n",
       "237   11/3/90    1.7     56   athletics    0      0      0   \n",
       "238   1/13/98   1.59     49  gymnastics    0      0      0   \n",
       "239    2/5/88    1.7     80   athletics    0      0      0   \n",
       "240   6/18/91   1.83     75   wrestling    0      0      0   \n",
       "\n",
       "                                   name2                             WikiLink  \\\n",
       "0                Abdullah_Abkar_Mohammed              Abdullah_Abkar_Mohammed   \n",
       "1                          Aida_Shanaeva                        Aida_Shanaeva   \n",
       "2    Aikaterini-Maria_Kontochristopoulou  Aikaterini-Maria_Kontochristopoulou   \n",
       "3                          Aisha_Praught                        Aisha_Praught   \n",
       "4                         Ajla_del_Ponte                       Ajla_del_Ponte   \n",
       "..                                   ...                                  ...   \n",
       "236                  Yekaterina_Smirnova        Yekaterina_Smirnova(canoeist)   \n",
       "237                       Yelena_Ryabova                       Yelena_Ryabova   \n",
       "238                        Yuki_Uchiyama     Yuki_Uchiyama_(artistic_gymnast)   \n",
       "239                     Zalina_Marghieva                     Zalina_Marghieva   \n",
       "240                  Zurabi_Datunashvili                  Zurabi_Datunashvili   \n",
       "\n",
       "                        RE_WikiLink  \n",
       "0                    Abdullah_Abkar  \n",
       "1                    Aida_Shanayeva  \n",
       "2     Aikaterini_Kontochristopoulou  \n",
       "3                Aisha_Praught-Leer  \n",
       "4                    Ajla_Del_Ponte  \n",
       "..                              ...  \n",
       "236  Yekaterina_Smirnova_(canoeist)  \n",
       "237                  Ýelena_Rýabowa  \n",
       "238         Yuki_Uchiyama_(gymnast)  \n",
       "239              Zalina_Petrivskaya  \n",
       "240              Zurab_Datunashvili  \n",
       "\n",
       "[241 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a_RE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re download atheletes wikipedia pages with the new correct wikilink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadRE(df,nodetype):\n",
    "    \"\"\" This functions Downloads the Wikipages \n",
    "    from Wikilinks column in the dataframe\n",
    "    \n",
    "    Input: dataframe and nodetype\n",
    "    -------------------------------\n",
    "    Output: \n",
    "    \"\"\"\n",
    "    for i in range(df.shape[0]):                                             # Run through all wikilinks in dataframe \n",
    "        baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "        action = \"action=query\"\n",
    "        title = \"titles=\" + df[\"RE_WikiLink\"].iloc[i]\n",
    "        content = \"prop=revisions&rvprop=content\"\n",
    "        dataformat =\"format=json\"\n",
    "        query = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat).encode('ascii', 'ignore').decode('ascii')\n",
    "        \n",
    "        wikiresponse = urllib.request.urlopen(query)                         \n",
    "        wikidata = wikiresponse.read()                                       \n",
    "        wikitext = wikidata.decode('utf-8')\n",
    "        wikijson = json.loads(wikitext)['query']['pages']\n",
    "        key = list(wikijson.keys())[0]\n",
    "\n",
    "        if key != '-1':                                                      # If Key = '-1',the wikilink does not exist \n",
    "            wiki_Print = wikijson[key]['revisions'][0]['*']\n",
    "            sys.stdout = open(nodetype + \"_\" + df[\"WikiLink\"].iloc[i] + \".txt\", \"w\",encoding=\"utf-8\")\n",
    "            print(wiki_Print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadRE(df_a_RE,'athletes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are still are athletes with incorrect wikilinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>nationality</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>sport</th>\n",
       "      <th>gold</th>\n",
       "      <th>silver</th>\n",
       "      <th>bronze</th>\n",
       "      <th>name2</th>\n",
       "      <th>WikiLink</th>\n",
       "      <th>RE_WikiLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74286490</td>\n",
       "      <td>Aldemir da Silva Junior</td>\n",
       "      <td>BRA</td>\n",
       "      <td>male</td>\n",
       "      <td>6/8/92</td>\n",
       "      <td>1.93</td>\n",
       "      <td>80</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aldemir_da_Silva_Junior</td>\n",
       "      <td>Aldemir_da_Silva_Junior</td>\n",
       "      <td>Aldemir_da_Silva_Júnior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>949130459</td>\n",
       "      <td>Almir Velagic</td>\n",
       "      <td>GER</td>\n",
       "      <td>male</td>\n",
       "      <td>8/22/81</td>\n",
       "      <td>1.83</td>\n",
       "      <td>149</td>\n",
       "      <td>weightlifting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Almir_Velagic</td>\n",
       "      <td>Almir_Velagic</td>\n",
       "      <td>Almir_Velagić</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931620156</td>\n",
       "      <td>Andrea Miklos</td>\n",
       "      <td>ROU</td>\n",
       "      <td>female</td>\n",
       "      <td>4/17/99</td>\n",
       "      <td>1.65</td>\n",
       "      <td>51</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrea_Miklos</td>\n",
       "      <td>Andrea_Miklos</td>\n",
       "      <td>Andrea_Miklós</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>560710110</td>\n",
       "      <td>Assiya Ipek</td>\n",
       "      <td>TUR</td>\n",
       "      <td>female</td>\n",
       "      <td>12/5/93</td>\n",
       "      <td>1.68</td>\n",
       "      <td>70</td>\n",
       "      <td>weightlifting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Assiya_Ipek</td>\n",
       "      <td>Assiya_Ipek</td>\n",
       "      <td>Assiya_İpek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>573831491</td>\n",
       "      <td>Barbara Riveros</td>\n",
       "      <td>CHI</td>\n",
       "      <td>female</td>\n",
       "      <td>8/3/87</td>\n",
       "      <td>1.57</td>\n",
       "      <td>46</td>\n",
       "      <td>triathlon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Barbara_Riveros</td>\n",
       "      <td>Barbara_Riveros</td>\n",
       "      <td>Bárbara_Riveros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>857144847</td>\n",
       "      <td>Benjamin Enzema</td>\n",
       "      <td>GEQ</td>\n",
       "      <td>male</td>\n",
       "      <td>3/25/89</td>\n",
       "      <td>1.7</td>\n",
       "      <td>63</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benjamin_Enzema</td>\n",
       "      <td>Benjamin_Enzema</td>\n",
       "      <td>Benjamín_Enzema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>908812309</td>\n",
       "      <td>Chloe Dygert</td>\n",
       "      <td>USA</td>\n",
       "      <td>female</td>\n",
       "      <td>1/1/97</td>\n",
       "      <td>1.76</td>\n",
       "      <td>66</td>\n",
       "      <td>cycling</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Chloe_Dygert</td>\n",
       "      <td>Chloe_Dygert</td>\n",
       "      <td>Chloé_Dygert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150543887</td>\n",
       "      <td>Chloe Tutton</td>\n",
       "      <td>GBR</td>\n",
       "      <td>female</td>\n",
       "      <td>7/17/96</td>\n",
       "      <td>1.68</td>\n",
       "      <td>62</td>\n",
       "      <td>aquatics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chloe_Tutton</td>\n",
       "      <td>Chloe_Tutton</td>\n",
       "      <td>Chloé_Tutton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128511976</td>\n",
       "      <td>Daniyar Ismayilov</td>\n",
       "      <td>TUR</td>\n",
       "      <td>male</td>\n",
       "      <td>2/3/92</td>\n",
       "      <td>1.73</td>\n",
       "      <td>69</td>\n",
       "      <td>weightlifting</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniyar_Ismayilov</td>\n",
       "      <td>Daniyar_Ismayilov</td>\n",
       "      <td>Daniyar_İsmayilov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>484914459</td>\n",
       "      <td>Desiree Henry</td>\n",
       "      <td>GBR</td>\n",
       "      <td>female</td>\n",
       "      <td>8/26/95</td>\n",
       "      <td>1.71</td>\n",
       "      <td>64</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Desiree_Henry</td>\n",
       "      <td>Desiree_Henry</td>\n",
       "      <td>Desirèe_Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>659584369</td>\n",
       "      <td>Edgar Crespo</td>\n",
       "      <td>PAN</td>\n",
       "      <td>male</td>\n",
       "      <td>5/11/89</td>\n",
       "      <td>1.78</td>\n",
       "      <td>83</td>\n",
       "      <td>aquatics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Edgar_Crespo</td>\n",
       "      <td>Edgar_Crespo</td>\n",
       "      <td>Édgar_Crespo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>367849834</td>\n",
       "      <td>Eduardo Sepulveda</td>\n",
       "      <td>ARG</td>\n",
       "      <td>male</td>\n",
       "      <td>6/13/91</td>\n",
       "      <td>1.73</td>\n",
       "      <td>63</td>\n",
       "      <td>cycling</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Eduardo_Sepulveda</td>\n",
       "      <td>Eduardo_Sepulveda</td>\n",
       "      <td>Eduardo_Sepúlveda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>576762169</td>\n",
       "      <td>Felix Denayer</td>\n",
       "      <td>BEL</td>\n",
       "      <td>male</td>\n",
       "      <td>1/31/90</td>\n",
       "      <td>1.9</td>\n",
       "      <td>85</td>\n",
       "      <td>hockey</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Felix_Denayer</td>\n",
       "      <td>Felix_Denayer</td>\n",
       "      <td>Félix_Denayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>352965099</td>\n",
       "      <td>Ferhat Arican</td>\n",
       "      <td>TUR</td>\n",
       "      <td>male</td>\n",
       "      <td>7/28/93</td>\n",
       "      <td>1.78</td>\n",
       "      <td>68</td>\n",
       "      <td>gymnastics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ferhat_Arican</td>\n",
       "      <td>Ferhat_Arican</td>\n",
       "      <td>Ferhat_Arıcan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70220465</td>\n",
       "      <td>Gulbadam Babamuratova</td>\n",
       "      <td>TKM</td>\n",
       "      <td>female</td>\n",
       "      <td>8/24/91</td>\n",
       "      <td>1.56</td>\n",
       "      <td>52</td>\n",
       "      <td>judo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gulbadam_Babamuratova</td>\n",
       "      <td>Gulbadam_Babamuratova</td>\n",
       "      <td>Gülbadam_Babamuratowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>699962258</td>\n",
       "      <td>Gulnabat Kadyrova</td>\n",
       "      <td>TKM</td>\n",
       "      <td>female</td>\n",
       "      <td>6/14/94</td>\n",
       "      <td>1.65</td>\n",
       "      <td>69</td>\n",
       "      <td>weightlifting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gulnabat_Kadyrova</td>\n",
       "      <td>Gulnabat_Kadyrova</td>\n",
       "      <td>Gülnabat_Kadyrowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>952258564</td>\n",
       "      <td>Inaki Gomez</td>\n",
       "      <td>CAN</td>\n",
       "      <td>male</td>\n",
       "      <td>1/16/88</td>\n",
       "      <td>1.72</td>\n",
       "      <td>59</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Inaki_Gomez</td>\n",
       "      <td>Inaki_Gomez</td>\n",
       "      <td>Iñaki_Gómez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>471014946</td>\n",
       "      <td>Ines Boubakri</td>\n",
       "      <td>TUN</td>\n",
       "      <td>female</td>\n",
       "      <td>12/28/88</td>\n",
       "      <td>1.67</td>\n",
       "      <td>56</td>\n",
       "      <td>fencing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ines_Boubakri</td>\n",
       "      <td>Ines_Boubakri</td>\n",
       "      <td>Inès_Boubakri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44722554</td>\n",
       "      <td>Jose Carlos Herrera</td>\n",
       "      <td>MEX</td>\n",
       "      <td>male</td>\n",
       "      <td>2/5/86</td>\n",
       "      <td>1.87</td>\n",
       "      <td>81</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jose_Carlos_Herrera</td>\n",
       "      <td>Jose_Carlos_Herrera</td>\n",
       "      <td>José_Carlos_Herrera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>224527761</td>\n",
       "      <td>Kibwe Johnson</td>\n",
       "      <td>USA</td>\n",
       "      <td>male</td>\n",
       "      <td>7/17/81</td>\n",
       "      <td>1.88</td>\n",
       "      <td>102</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kibwe_Johnson</td>\n",
       "      <td>Kibwe_Johnson</td>\n",
       "      <td>Kibwé_Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22717911</td>\n",
       "      <td>Luisa Kiala</td>\n",
       "      <td>ANG</td>\n",
       "      <td>female</td>\n",
       "      <td>1/25/82</td>\n",
       "      <td>1.8</td>\n",
       "      <td>62</td>\n",
       "      <td>handball</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Luisa_Kiala</td>\n",
       "      <td>Luisa_Kiala</td>\n",
       "      <td>Luísa_Kiala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>706961920</td>\n",
       "      <td>Luisito Pie</td>\n",
       "      <td>DOM</td>\n",
       "      <td>male</td>\n",
       "      <td>3/4/94</td>\n",
       "      <td>1.83</td>\n",
       "      <td>57</td>\n",
       "      <td>taekwondo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Luisito_Pie</td>\n",
       "      <td>Luisito_Pie</td>\n",
       "      <td>Luisito_Pié</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>744094711</td>\n",
       "      <td>Mamadou Kasse Hann</td>\n",
       "      <td>FRA</td>\n",
       "      <td>male</td>\n",
       "      <td>10/10/86</td>\n",
       "      <td>1.89</td>\n",
       "      <td>79</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mamadou_Kasse_Hann</td>\n",
       "      <td>Mamadou_Kasse_Hann</td>\n",
       "      <td>Mamadou_Kassé_Hann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>947717856</td>\n",
       "      <td>Maoulida Daroueche</td>\n",
       "      <td>COM</td>\n",
       "      <td>male</td>\n",
       "      <td>2/7/90</td>\n",
       "      <td>1.77</td>\n",
       "      <td>60</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Maoulida_Daroueche</td>\n",
       "      <td>Maoulida_Daroueche</td>\n",
       "      <td>Maoulida_Darouèche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>432314163</td>\n",
       "      <td>Marcio Teles</td>\n",
       "      <td>BRA</td>\n",
       "      <td>male</td>\n",
       "      <td>1/27/94</td>\n",
       "      <td>1.8</td>\n",
       "      <td>68</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marcio_Teles</td>\n",
       "      <td>Marcio_Teles</td>\n",
       "      <td>Márcio_Teles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>63803519</td>\n",
       "      <td>Maris Strombergs</td>\n",
       "      <td>LAT</td>\n",
       "      <td>male</td>\n",
       "      <td>3/10/87</td>\n",
       "      <td>1.86</td>\n",
       "      <td>90</td>\n",
       "      <td>cycling</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Maris_Strombergs</td>\n",
       "      <td>Maris_Strombergs</td>\n",
       "      <td>Māris_Štrombergs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>668487554</td>\n",
       "      <td>Maritza Guaman</td>\n",
       "      <td>ECU</td>\n",
       "      <td>female</td>\n",
       "      <td>1/15/88</td>\n",
       "      <td>1.55</td>\n",
       "      <td>47</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Maritza_Guaman</td>\n",
       "      <td>Maritza_Guaman</td>\n",
       "      <td>Maritza_Guamán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>770839524</td>\n",
       "      <td>Mickael-Meba Zeze</td>\n",
       "      <td>FRA</td>\n",
       "      <td>male</td>\n",
       "      <td>5/19/94</td>\n",
       "      <td>1.75</td>\n",
       "      <td>65</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mickael-Meba_Zeze</td>\n",
       "      <td>Mickael-Meba_Zeze</td>\n",
       "      <td>Méba-Mickaël_Zeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>772765503</td>\n",
       "      <td>Narcis Stefan Mihaila</td>\n",
       "      <td>ROU</td>\n",
       "      <td>male</td>\n",
       "      <td>8/4/87</td>\n",
       "      <td>1.83</td>\n",
       "      <td>73</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Narcis_Stefan_Mihaila</td>\n",
       "      <td>Narcis_Stefan_Mihaila</td>\n",
       "      <td>Narcis_Mihăilă</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>628099211</td>\n",
       "      <td>Nestor Nielsen van Hoff</td>\n",
       "      <td>URU</td>\n",
       "      <td>male</td>\n",
       "      <td>11/13/72</td>\n",
       "      <td>1.81</td>\n",
       "      <td>83</td>\n",
       "      <td>equestrian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nestor_Nielsen_van_Hoff</td>\n",
       "      <td>Nestor_Nielsen_van_Hoff</td>\n",
       "      <td>Néstor_Nielsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>860526701</td>\n",
       "      <td>Nozomi Sato</td>\n",
       "      <td>JPN</td>\n",
       "      <td>female</td>\n",
       "      <td>7/3/86</td>\n",
       "      <td>1.73</td>\n",
       "      <td>61</td>\n",
       "      <td>fencing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nozomi_Sato</td>\n",
       "      <td>Nozomi_Sato</td>\n",
       "      <td>Nozomi_Satō</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>608348414</td>\n",
       "      <td>Pamela Nogueira</td>\n",
       "      <td>BRA</td>\n",
       "      <td>female</td>\n",
       "      <td>7/17/88</td>\n",
       "      <td>1.64</td>\n",
       "      <td>54</td>\n",
       "      <td>aquatics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pamela_Nogueira</td>\n",
       "      <td>Pamela_Nogueira</td>\n",
       "      <td>Pâmela_Nogueira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>618669054</td>\n",
       "      <td>Patricia Mamona</td>\n",
       "      <td>POR</td>\n",
       "      <td>female</td>\n",
       "      <td>11/21/88</td>\n",
       "      <td>1.67</td>\n",
       "      <td>60</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Patricia_Mamona</td>\n",
       "      <td>Patricia_Mamona</td>\n",
       "      <td>Patrícia_Mamona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>927721952</td>\n",
       "      <td>Paula Kania</td>\n",
       "      <td>POL</td>\n",
       "      <td>female</td>\n",
       "      <td>11/6/92</td>\n",
       "      <td>1.73</td>\n",
       "      <td>63</td>\n",
       "      <td>tennis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paula_Kania</td>\n",
       "      <td>Paula_Kania</td>\n",
       "      <td>Paula_Kania-Choduń</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>990523633</td>\n",
       "      <td>Paula Lynn Obanana</td>\n",
       "      <td>USA</td>\n",
       "      <td>female</td>\n",
       "      <td>3/19/85</td>\n",
       "      <td>1.61</td>\n",
       "      <td>58</td>\n",
       "      <td>badminton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paula_Lynn_Obanana</td>\n",
       "      <td>Paula_Lynn_Obanana</td>\n",
       "      <td>Paula_Lynn_Obañana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>250731306</td>\n",
       "      <td>Paulina Buziak</td>\n",
       "      <td>POL</td>\n",
       "      <td>female</td>\n",
       "      <td>12/16/86</td>\n",
       "      <td>1.7</td>\n",
       "      <td>48</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paulina_Buziak</td>\n",
       "      <td>Paulina_Buziak</td>\n",
       "      <td>Paulina_Buziak-Śmiatacz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>595693599</td>\n",
       "      <td>Pedro da Silva</td>\n",
       "      <td>BRA</td>\n",
       "      <td>male</td>\n",
       "      <td>4/12/93</td>\n",
       "      <td>1.76</td>\n",
       "      <td>69</td>\n",
       "      <td>canoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pedro_da_Silva</td>\n",
       "      <td>Pedro_da_Silva_(canoeist)</td>\n",
       "      <td>Pepe_Gonçalves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>400301052</td>\n",
       "      <td>Rene Toft Hansen</td>\n",
       "      <td>DEN</td>\n",
       "      <td>male</td>\n",
       "      <td>11/1/84</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>handball</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rene_Toft_Hansen</td>\n",
       "      <td>Rene_Toft_Hansen</td>\n",
       "      <td>René_Toft_Hansen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>333696204</td>\n",
       "      <td>Rushana Nurjavova</td>\n",
       "      <td>TKM</td>\n",
       "      <td>female</td>\n",
       "      <td>6/22/94</td>\n",
       "      <td>1.65</td>\n",
       "      <td>57</td>\n",
       "      <td>judo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rushana_Nurjavova</td>\n",
       "      <td>Rushana_Nurjavova</td>\n",
       "      <td>Ruşana_Nurjawowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>266769451</td>\n",
       "      <td>Sebastien Dockier</td>\n",
       "      <td>BEL</td>\n",
       "      <td>male</td>\n",
       "      <td>12/28/89</td>\n",
       "      <td>1.75</td>\n",
       "      <td>74</td>\n",
       "      <td>hockey</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sebastien_Dockier</td>\n",
       "      <td>Sebastien_Dockier</td>\n",
       "      <td>Sébastien_Dockier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>43374597</td>\n",
       "      <td>Sumiya Dorjsuren</td>\n",
       "      <td>MGL</td>\n",
       "      <td>female</td>\n",
       "      <td>3/11/91</td>\n",
       "      <td>1.6</td>\n",
       "      <td>59</td>\n",
       "      <td>judo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sumiya_Dorjsuren</td>\n",
       "      <td>Sumiya_Dorjsuren</td>\n",
       "      <td>Dorjsürengiin_Sumiyaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>539157373</td>\n",
       "      <td>Taha Akgul</td>\n",
       "      <td>TUR</td>\n",
       "      <td>male</td>\n",
       "      <td>11/22/90</td>\n",
       "      <td>1.92</td>\n",
       "      <td>125</td>\n",
       "      <td>wrestling</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taha_Akgul</td>\n",
       "      <td>Taha_Akgul</td>\n",
       "      <td>Taha_Akgül</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>477856605</td>\n",
       "      <td>Victor Ortega</td>\n",
       "      <td>COL</td>\n",
       "      <td>male</td>\n",
       "      <td>1/27/88</td>\n",
       "      <td>1.72</td>\n",
       "      <td>68</td>\n",
       "      <td>aquatics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Victor_Ortega</td>\n",
       "      <td>Victor_Ortega</td>\n",
       "      <td>Víctor_Ortega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>732110114</td>\n",
       "      <td>Vlad-Dragos Aicoboae</td>\n",
       "      <td>ROU</td>\n",
       "      <td>male</td>\n",
       "      <td>10/10/93</td>\n",
       "      <td>1.97</td>\n",
       "      <td>91</td>\n",
       "      <td>rowing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Vlad-Dragos_Aicoboae</td>\n",
       "      <td>Vlad-Dragos_Aicoboae</td>\n",
       "      <td>Vlad_Dragoș_Aicoboae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>805715080</td>\n",
       "      <td>Yelena Ryabova</td>\n",
       "      <td>TKM</td>\n",
       "      <td>female</td>\n",
       "      <td>11/3/90</td>\n",
       "      <td>1.7</td>\n",
       "      <td>56</td>\n",
       "      <td>athletics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yelena_Ryabova</td>\n",
       "      <td>Yelena_Ryabova</td>\n",
       "      <td>Ýelena_Rýabowa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                     name nationality     sex       dob height  \\\n",
       "0    74286490  Aldemir da Silva Junior         BRA    male    6/8/92   1.93   \n",
       "1   949130459            Almir Velagic         GER    male   8/22/81   1.83   \n",
       "2   931620156            Andrea Miklos         ROU  female   4/17/99   1.65   \n",
       "3   560710110              Assiya Ipek         TUR  female   12/5/93   1.68   \n",
       "4   573831491          Barbara Riveros         CHI  female    8/3/87   1.57   \n",
       "5   857144847          Benjamin Enzema         GEQ    male   3/25/89    1.7   \n",
       "6   908812309             Chloe Dygert         USA  female    1/1/97   1.76   \n",
       "7   150543887             Chloe Tutton         GBR  female   7/17/96   1.68   \n",
       "8   128511976        Daniyar Ismayilov         TUR    male    2/3/92   1.73   \n",
       "9   484914459            Desiree Henry         GBR  female   8/26/95   1.71   \n",
       "10  659584369             Edgar Crespo         PAN    male   5/11/89   1.78   \n",
       "11  367849834        Eduardo Sepulveda         ARG    male   6/13/91   1.73   \n",
       "12  576762169            Felix Denayer         BEL    male   1/31/90    1.9   \n",
       "13  352965099            Ferhat Arican         TUR    male   7/28/93   1.78   \n",
       "14   70220465    Gulbadam Babamuratova         TKM  female   8/24/91   1.56   \n",
       "15  699962258        Gulnabat Kadyrova         TKM  female   6/14/94   1.65   \n",
       "16  952258564              Inaki Gomez         CAN    male   1/16/88   1.72   \n",
       "17  471014946            Ines Boubakri         TUN  female  12/28/88   1.67   \n",
       "18   44722554      Jose Carlos Herrera         MEX    male    2/5/86   1.87   \n",
       "19  224527761            Kibwe Johnson         USA    male   7/17/81   1.88   \n",
       "20   22717911              Luisa Kiala         ANG  female   1/25/82    1.8   \n",
       "21  706961920              Luisito Pie         DOM    male    3/4/94   1.83   \n",
       "22  744094711       Mamadou Kasse Hann         FRA    male  10/10/86   1.89   \n",
       "23  947717856       Maoulida Daroueche         COM    male    2/7/90   1.77   \n",
       "24  432314163             Marcio Teles         BRA    male   1/27/94    1.8   \n",
       "25   63803519         Maris Strombergs         LAT    male   3/10/87   1.86   \n",
       "26  668487554           Maritza Guaman         ECU  female   1/15/88   1.55   \n",
       "27  770839524        Mickael-Meba Zeze         FRA    male   5/19/94   1.75   \n",
       "28  772765503    Narcis Stefan Mihaila         ROU    male    8/4/87   1.83   \n",
       "29  628099211  Nestor Nielsen van Hoff         URU    male  11/13/72   1.81   \n",
       "30  860526701              Nozomi Sato         JPN  female    7/3/86   1.73   \n",
       "31  608348414          Pamela Nogueira         BRA  female   7/17/88   1.64   \n",
       "32  618669054          Patricia Mamona         POR  female  11/21/88   1.67   \n",
       "33  927721952              Paula Kania         POL  female   11/6/92   1.73   \n",
       "34  990523633       Paula Lynn Obanana         USA  female   3/19/85   1.61   \n",
       "35  250731306           Paulina Buziak         POL  female  12/16/86    1.7   \n",
       "36  595693599           Pedro da Silva         BRA    male   4/12/93   1.76   \n",
       "37  400301052         Rene Toft Hansen         DEN    male   11/1/84      2   \n",
       "38  333696204        Rushana Nurjavova         TKM  female   6/22/94   1.65   \n",
       "39  266769451        Sebastien Dockier         BEL    male  12/28/89   1.75   \n",
       "40   43374597         Sumiya Dorjsuren         MGL  female   3/11/91    1.6   \n",
       "41  539157373               Taha Akgul         TUR    male  11/22/90   1.92   \n",
       "42  477856605            Victor Ortega         COL    male   1/27/88   1.72   \n",
       "43  732110114     Vlad-Dragos Aicoboae         ROU    male  10/10/93   1.97   \n",
       "44  805715080           Yelena Ryabova         TKM  female   11/3/90    1.7   \n",
       "\n",
       "   weight          sport gold silver bronze                    name2  \\\n",
       "0      80      athletics    0      0      0  Aldemir_da_Silva_Junior   \n",
       "1     149  weightlifting    0      0      0            Almir_Velagic   \n",
       "2      51      athletics    0      0      0            Andrea_Miklos   \n",
       "3      70  weightlifting    0      0      0              Assiya_Ipek   \n",
       "4      46      triathlon    0      0      0          Barbara_Riveros   \n",
       "5      63      athletics    0      0      0          Benjamin_Enzema   \n",
       "6      66        cycling    0      1      0             Chloe_Dygert   \n",
       "7      62       aquatics    0      0      0             Chloe_Tutton   \n",
       "8      69  weightlifting    0      1      0        Daniyar_Ismayilov   \n",
       "9      64      athletics    0      0      1            Desiree_Henry   \n",
       "10     83       aquatics    0      0      0             Edgar_Crespo   \n",
       "11     63        cycling    0      0      0        Eduardo_Sepulveda   \n",
       "12     85         hockey    0      1      0            Felix_Denayer   \n",
       "13     68     gymnastics    0      0      0            Ferhat_Arican   \n",
       "14     52           judo    0      0      0    Gulbadam_Babamuratova   \n",
       "15     69  weightlifting    0      0      0        Gulnabat_Kadyrova   \n",
       "16     59      athletics    0      0      0              Inaki_Gomez   \n",
       "17     56        fencing    0      0      1            Ines_Boubakri   \n",
       "18     81      athletics    0      0      0      Jose_Carlos_Herrera   \n",
       "19    102      athletics    0      0      0            Kibwe_Johnson   \n",
       "20     62       handball    0      0      0              Luisa_Kiala   \n",
       "21     57      taekwondo    0      0      1              Luisito_Pie   \n",
       "22     79      athletics    0      0      0       Mamadou_Kasse_Hann   \n",
       "23     60      athletics    0      0      0       Maoulida_Daroueche   \n",
       "24     68      athletics    0      0      0             Marcio_Teles   \n",
       "25     90        cycling    0      0      0         Maris_Strombergs   \n",
       "26     47      athletics    0      0      0           Maritza_Guaman   \n",
       "27     65      athletics    0      0      0        Mickael-Meba_Zeze   \n",
       "28     73      athletics    0      0      0    Narcis_Stefan_Mihaila   \n",
       "29     83     equestrian    0      0      0  Nestor_Nielsen_van_Hoff   \n",
       "30     61        fencing    0      0      0              Nozomi_Sato   \n",
       "31     54       aquatics    0      0      0          Pamela_Nogueira   \n",
       "32     60      athletics    0      0      0          Patricia_Mamona   \n",
       "33     63         tennis    0      0      0              Paula_Kania   \n",
       "34     58      badminton    0      0      0       Paula_Lynn_Obanana   \n",
       "35     48      athletics    0      0      0           Paulina_Buziak   \n",
       "36     69          canoe    0      0      0           Pedro_da_Silva   \n",
       "37    105       handball    1      0      0         Rene_Toft_Hansen   \n",
       "38     57           judo    0      0      0        Rushana_Nurjavova   \n",
       "39     74         hockey    0      1      0        Sebastien_Dockier   \n",
       "40     59           judo    0      1      0         Sumiya_Dorjsuren   \n",
       "41    125      wrestling    1      0      0               Taha_Akgul   \n",
       "42     68       aquatics    0      0      0            Victor_Ortega   \n",
       "43     91         rowing    0      0      0     Vlad-Dragos_Aicoboae   \n",
       "44     56      athletics    0      0      0           Yelena_Ryabova   \n",
       "\n",
       "                     WikiLink              RE_WikiLink  \n",
       "0     Aldemir_da_Silva_Junior  Aldemir_da_Silva_Júnior  \n",
       "1               Almir_Velagic            Almir_Velagić  \n",
       "2               Andrea_Miklos            Andrea_Miklós  \n",
       "3                 Assiya_Ipek              Assiya_İpek  \n",
       "4             Barbara_Riveros          Bárbara_Riveros  \n",
       "5             Benjamin_Enzema          Benjamín_Enzema  \n",
       "6                Chloe_Dygert             Chloé_Dygert  \n",
       "7                Chloe_Tutton             Chloé_Tutton  \n",
       "8           Daniyar_Ismayilov        Daniyar_İsmayilov  \n",
       "9               Desiree_Henry            Desirèe_Henry  \n",
       "10               Edgar_Crespo             Édgar_Crespo  \n",
       "11          Eduardo_Sepulveda        Eduardo_Sepúlveda  \n",
       "12              Felix_Denayer            Félix_Denayer  \n",
       "13              Ferhat_Arican            Ferhat_Arıcan  \n",
       "14      Gulbadam_Babamuratova    Gülbadam_Babamuratowa  \n",
       "15          Gulnabat_Kadyrova        Gülnabat_Kadyrowa  \n",
       "16                Inaki_Gomez              Iñaki_Gómez  \n",
       "17              Ines_Boubakri            Inès_Boubakri  \n",
       "18        Jose_Carlos_Herrera      José_Carlos_Herrera  \n",
       "19              Kibwe_Johnson            Kibwé_Johnson  \n",
       "20                Luisa_Kiala              Luísa_Kiala  \n",
       "21                Luisito_Pie              Luisito_Pié  \n",
       "22         Mamadou_Kasse_Hann       Mamadou_Kassé_Hann  \n",
       "23         Maoulida_Daroueche       Maoulida_Darouèche  \n",
       "24               Marcio_Teles             Márcio_Teles  \n",
       "25           Maris_Strombergs         Māris_Štrombergs  \n",
       "26             Maritza_Guaman           Maritza_Guamán  \n",
       "27          Mickael-Meba_Zeze        Méba-Mickaël_Zeze  \n",
       "28      Narcis_Stefan_Mihaila           Narcis_Mihăilă  \n",
       "29    Nestor_Nielsen_van_Hoff           Néstor_Nielsen  \n",
       "30                Nozomi_Sato              Nozomi_Satō  \n",
       "31            Pamela_Nogueira          Pâmela_Nogueira  \n",
       "32            Patricia_Mamona          Patrícia_Mamona  \n",
       "33                Paula_Kania       Paula_Kania-Choduń  \n",
       "34         Paula_Lynn_Obanana       Paula_Lynn_Obañana  \n",
       "35             Paulina_Buziak  Paulina_Buziak-Śmiatacz  \n",
       "36  Pedro_da_Silva_(canoeist)           Pepe_Gonçalves  \n",
       "37           Rene_Toft_Hansen         René_Toft_Hansen  \n",
       "38          Rushana_Nurjavova         Ruşana_Nurjawowa  \n",
       "39          Sebastien_Dockier        Sébastien_Dockier  \n",
       "40           Sumiya_Dorjsuren    Dorjsürengiin_Sumiyaa  \n",
       "41                 Taha_Akgul               Taha_Akgül  \n",
       "42              Victor_Ortega            Víctor_Ortega  \n",
       "43       Vlad-Dragos_Aicoboae     Vlad_Dragoș_Aicoboae  \n",
       "44             Yelena_Ryabova           Ýelena_Rýabowa  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RE_WikiLink = Athlet_REDIRECT_WikiLink(df_a)                         # Run Function\n",
    "df_if = pd.DataFrame(RE_WikiLink, columns = ['id', 'RE_WikiLink'])   # Convert wikilink list into panda dataframe\n",
    "df_a_RE = df_a.merge(df_if)                                          # Merge wikilink dataframe and athletes dataframe\n",
    "\n",
    "df_a_RE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the REDIRECTED Wikipedia pages cannot be downloaded due to f.eks. the name consists of an 'é'. Therefore these 44 athletes will be removed from the dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove #REDIRECT from dataframe:\n",
    "df_a = df_a[~df_a.id.isin(df_a_RE.id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Olympic Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to create a networkx graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLinksAndRemove(f,df1,df2,df3):\n",
    "    \"\"\" Helperfunction to find links in wikipages \n",
    "    and remove the link if it is not a wikilink \n",
    "    in the dataframes.\n",
    "    \n",
    "    Input: the file, and the 3 dataframes\n",
    "    -------------------------------\n",
    "    Output: list of edges\n",
    "    \"\"\"\n",
    "    links = re.findall(\"\\[\\[(.*?)\\]\\]\", f)                         # Use a regular expression to extract all outgoing links\n",
    "    links = [x.replace(' ','_') for x in links]                    # Replace space with _\n",
    "    links = [s.split('|') for s in links]                          # Split the links by the '|'\n",
    "    \n",
    "    \n",
    "    edges = []                                                     # An empty list for edges\n",
    "    for i in range(len(links)):                                    # Run through all links\n",
    "                                                                   # For each link, check if the target is in the data.\n",
    "        if len(df1.loc[df1['WikiLink'] == links[i][0]]) >= 1 or len(df2.loc[df2['WikiLink'] == links[i][0]]) >= 1 or len(df3.loc[df3['WikiLink'] == links[i][0]]) >= 1:\n",
    "            edges.append(links[i][0])                              # If yes add the link to the edge list. If no, discard it.\n",
    "    return(edges)\n",
    "\n",
    "\n",
    "def AddNodes(G, df, nodetype):\n",
    "    \"\"\" Function to add nodes to the graph. \n",
    "    Every wikilink in the data is a node in the graph.\n",
    "     \n",
    "    Input: The NetworkX DiGraph, The dataframe and the nodetype\n",
    "    -------------------------------\n",
    "    Output: The NetworkX DiGraph\n",
    "    \"\"\"\n",
    "    for i in range(df.shape[0]):                                  # Run through all wikilinks in the dataframe\n",
    "        G.add_node(df.WikiLink.iloc[i], nodetype = nodetype)      # Add the node to the Graph\n",
    " \n",
    "   \n",
    "def AddEdges(G, df1, df2, df3, nodetype):\n",
    "    \"\"\" Function to add edges to the graph. \n",
    "     \n",
    "    Input: The NetworkX DiGraph, all dataframe and the nodetype\n",
    "    -------------------------------\n",
    "    Output: The NetworkX DiGraph\n",
    "    \"\"\"\n",
    "    for i in range(df1.shape[0]):                                 # Run through all wikilinks in the dataframe                                                                  \n",
    "        Node = df1['WikiLink'].iloc[i]                            # Open the page file\n",
    "        f = io.open(nodetype + Node + \".txt\",'r',encoding = 'utf-8').read()\n",
    "        edgesTo = findLinksAndRemove(f,df1,df2,df3)               # Run the helperfuncktion to find links and remove the link if it is not in the data.\n",
    "        \n",
    "        for j in edgesTo:                                         # Run through all the finded edges\n",
    "            if j in list(G.nodes):                                # If the edge link to a node add edge to Graph\n",
    "                G.add_edge(Node, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a NetworkX DiGraph to store the network. Store also the properties of the nodes (i.e. from which dataframe they hail).\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add Nodes\n",
    "AddNodes(G, df_c, 'countries')\n",
    "AddNodes(G, df_e, 'sports')\n",
    "AddNodes(G, df_a, 'athletes')\n",
    "\n",
    "# Add edges\n",
    "AddEdges(G, df_c, df_e, df_a, 'countries_')\n",
    "AddEdges(G, df_e, df_c, df_a, 'events_')\n",
    "AddEdges(G, df_a, df_e, df_c, 'athletes_')\n",
    "\n",
    "# Check if nodes do not have any out- or in- degrees. These may discard from the network.\n",
    "remove = [node for node, degree in dict(G.degree()).items() if degree == 0]\n",
    "G.remove_nodes_from(remove) \n",
    "\n",
    "# Find largest connected_components\n",
    "largest_cc = max(nx.weakly_connected_components(G), key=len)\n",
    "G = G.subgraph(largest_cc).copy()\n",
    "\n",
    "# Add dataframes, ass attributes to the nodes\n",
    "node_attr_e = df_e.set_index('WikiLink').to_dict('index')\n",
    "node_attr_c = df_c.set_index('WikiLink').to_dict('index')\n",
    "node_attr_a = df_a.set_index('WikiLink').to_dict('index')\n",
    "nx.set_node_attributes(G, node_attr_e)\n",
    "nx.set_node_attributes(G, node_attr_c)\n",
    "nx.set_node_attributes(G, node_attr_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataframes and Network\n",
    "Finally, save the 3 cleaned dataframes and the network for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframes:\n",
    "pickle.dump(df_a, open('df_athletes.txt', 'wb'))\n",
    "pickle.dump(df_c, open('df_countries.txt', 'wb'))\n",
    "pickle.dump(df_e, open('df_events.txt', 'wb'))\n",
    "\n",
    "# Save the network\n",
    "pickle.dump(G, open('G.txt', 'wb'))\n",
    "\n",
    "# Save as the graph as .gexf for making an interactive graph plot in GEPHI with sigma js exporter. \n",
    "nx.write_gexf(G, \"G.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List with colors used in the explainer notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = {\n",
    "'aliceblue':            '#F0F8FF',\n",
    "'antiquewhite':         '#FAEBD7',\n",
    "'aqua':                 '#00FFFF',\n",
    "'aquamarine':           '#7FFFD4',\n",
    "'azure':                '#F0FFFF',\n",
    "'beige':                '#F5F5DC',\n",
    "'bisque':               '#FFE4C4',\n",
    "'black':                '#000000',\n",
    "'blanchedalmond':       '#FFEBCD',\n",
    "'blue':                 '#0000FF',\n",
    "'blueviolet':           '#8A2BE2',\n",
    "'brown':                '#A52A2A',\n",
    "'burlywood':            '#DEB887',\n",
    "'cadetblue':            '#5F9EA0',\n",
    "'chartreuse':           '#7FFF00',\n",
    "'chocolate':            '#D2691E',\n",
    "'coral':                '#FF7F50',\n",
    "'cornflowerblue':       '#6495ED',\n",
    "'cornsilk':             '#FFF8DC',\n",
    "'crimson':              '#DC143C',\n",
    "'cyan':                 '#00FFFF',\n",
    "'darkblue':             '#00008B',\n",
    "'darkcyan':             '#008B8B',\n",
    "'darkgoldenrod':        '#B8860B',\n",
    "'darkgray':             '#A9A9A9',\n",
    "'darkgreen':            '#006400',\n",
    "'darkkhaki':            '#BDB76B',\n",
    "'darkmagenta':          '#8B008B',\n",
    "'darkolivegreen':       '#556B2F',\n",
    "'darkorange':           '#FF8C00',\n",
    "'darkorchid':           '#9932CC',\n",
    "'darkred':              '#8B0000',\n",
    "'darksalmon':           '#E9967A',\n",
    "'darkseagreen':         '#8FBC8F',\n",
    "'darkslateblue':        '#483D8B',\n",
    "'darkslategray':        '#2F4F4F',\n",
    "'darkturquoise':        '#00CED1',\n",
    "'darkviolet':           '#9400D3',\n",
    "'deeppink':             '#FF1493',\n",
    "'deepskyblue':          '#00BFFF',\n",
    "'dimgray':              '#696969',\n",
    "'dodgerblue':           '#1E90FF',\n",
    "'firebrick':            '#B22222',\n",
    "'floralwhite':          '#FFFAF0',\n",
    "'forestgreen':          '#228B22',\n",
    "'fuchsia':              '#FF00FF',\n",
    "'gainsboro':            '#DCDCDC',\n",
    "'ghostwhite':           '#F8F8FF',\n",
    "'gold':                 '#FFD700',\n",
    "'goldenrod':            '#DAA520',\n",
    "'gray':                 '#808080',\n",
    "'green':                '#008000',\n",
    "'greenyellow':          '#ADFF2F',\n",
    "'honeydew':             '#F0FFF0',\n",
    "'hotpink':              '#FF69B4',\n",
    "'indianred':            '#CD5C5C',\n",
    "'indigo':               '#4B0082',\n",
    "'ivory':                '#FFFFF0',\n",
    "'khaki':                '#F0E68C',\n",
    "'lavender':             '#E6E6FA',\n",
    "'lavenderblush':        '#FFF0F5',\n",
    "'lawngreen':            '#7CFC00',\n",
    "'lemonchiffon':         '#FFFACD',\n",
    "'lightblue':            '#ADD8E6',\n",
    "'lightcoral':           '#F08080',\n",
    "'lightcyan':            '#E0FFFF',\n",
    "'lightgoldenrodyellow': '#FAFAD2',\n",
    "'lightgreen':           '#90EE90',\n",
    "'lightgray':            '#D3D3D3',\n",
    "'lightpink':            '#FFB6C1',\n",
    "'lightsalmon':          '#FFA07A',\n",
    "'lightseagreen':        '#20B2AA',\n",
    "'lightskyblue':         '#87CEFA',\n",
    "'lightslategray':       '#778899',\n",
    "'lightsteelblue':       '#B0C4DE',\n",
    "'lightyellow':          '#FFFFE0',\n",
    "'lime':                 '#00FF00',\n",
    "'limegreen':            '#32CD32',\n",
    "'linen':                '#FAF0E6',\n",
    "'magenta':              '#FF00FF',\n",
    "'maroon':               '#800000',\n",
    "'mediumaquamarine':     '#66CDAA',\n",
    "'mediumblue':           '#0000CD',\n",
    "'mediumorchid':         '#BA55D3',\n",
    "'mediumpurple':         '#9370DB',\n",
    "'mediumseagreen':       '#3CB371',\n",
    "'mediumslateblue':      '#7B68EE',\n",
    "'mediumspringgreen':    '#00FA9A',\n",
    "'mediumturquoise':      '#48D1CC',\n",
    "'mediumvioletred':      '#C71585',\n",
    "'midnightblue':         '#191970',\n",
    "'mintcream':            '#F5FFFA',\n",
    "'mistyrose':            '#FFE4E1',\n",
    "'moccasin':             '#FFE4B5',\n",
    "'navajowhite':          '#FFDEAD',\n",
    "'navy':                 '#000080',\n",
    "'oldlace':              '#FDF5E6',\n",
    "'olive':                '#808000',\n",
    "'olivedrab':            '#6B8E23',\n",
    "'orange':               '#FFA500',\n",
    "'orangered':            '#FF4500',\n",
    "'orchid':               '#DA70D6',\n",
    "'palegoldenrod':        '#EEE8AA',\n",
    "'palegreen':            '#98FB98',\n",
    "'paleturquoise':        '#AFEEEE',\n",
    "'palevioletred':        '#DB7093',\n",
    "'papayawhip':           '#FFEFD5',\n",
    "'peachpuff':            '#FFDAB9',\n",
    "'peru':                 '#CD853F',\n",
    "'pink':                 '#FFC0CB',\n",
    "'plum':                 '#DDA0DD',\n",
    "'powderblue':           '#B0E0E6',\n",
    "'purple':               '#800080',\n",
    "'red':                  '#FF0000',\n",
    "'rosybrown':            '#BC8F8F',\n",
    "'royalblue':            '#4169E1',\n",
    "'saddlebrown':          '#8B4513',\n",
    "'salmon':               '#FA8072',\n",
    "'sandybrown':           '#FAA460',\n",
    "'seagreen':             '#2E8B57',\n",
    "'seashell':             '#FFF5EE',\n",
    "'sienna':               '#A0522D',\n",
    "'silver':               '#C0C0C0',\n",
    "'skyblue':              '#87CEEB',\n",
    "'slateblue':            '#6A5ACD',\n",
    "'slategray':            '#708090',\n",
    "'snow':                 '#FFFAFA',\n",
    "'springgreen':          '#00FF7F',\n",
    "'steelblue':            '#4682B4',\n",
    "'tan':                  '#D2B48C',\n",
    "'teal':                 '#008080',\n",
    "'thistle':              '#D8BFD8',\n",
    "'tomato':               '#FF6347',\n",
    "'turquoise':            '#40E0D0',\n",
    "'violet':               '#EE82EE',\n",
    "'wheat':                '#F5DEB3',\n",
    "'white':                '#FFFFFF',\n",
    "'whitesmoke':           '#F5F5F5',\n",
    "'yellow':               '#FFFF00',\n",
    "'yellowgreen':          '#9ACD32'}\n",
    "\n",
    "# Save the graph.\n",
    "pickle.dump(cnames, open('cnames.txt', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
